import streamlit as st
import pandas as pd
import akasha
import os
import akasha.helper as ah
import shutil
import json
import docx2txt
from pptx import Presentation
from pypdf import PdfReader


st.set_page_config(page_title="CSW")
# --- 1. ç’°å¢ƒè¨­å®š ---
DATA_FOLDER = os.getenv("DATA_FOLDER", "data")
DEFAULT_DATA_FILE = os.getenv("DEFAULT_DATA_FILE", "default_data/FAQ_Default.xlsx")
os.makedirs(DATA_FOLDER, exist_ok=True)
DEFAULT_FILE = os.path.join(DATA_FOLDER, "FAQ_Default.xlsx")
DATA_STATE_PATH = "data_state.json"
ALLOWED_EXTS = {".xlsx", ".docx", ".txt", ".pdf", ".pptx"}
if not os.path.exists(DEFAULT_FILE):
    if not os.path.exists(DEFAULT_DATA_FILE):
        st.write(f"ç¼ºå°‘é è¨­æ–‡ä»¶{DEFAULT_DATA_FILE}ï¼Œè«‹å»ºç«‹è³‡æ–™å¤¾ default_data ä¸¦å°‡ FAQ_Default.xlsx å­˜å…¥å¾Œé‡æ–°æ•´ç†é é¢ã€‚")
        st.stop()
    else:
        shutil.copy(DEFAULT_DATA_FILE, DEFAULT_FILE)
ACTIVE_FILE = os.path.join(DATA_FOLDER, "FAQ_Active.xlsx")

MODEL_CONFIG = {
    "Google Gemini(2.5-flash)": {
        "env_var": "GEMINI_API_KEY",
        "model_name": "gemini:gemini-2.5-flash"
    },
    "OpenAI (GPT-4o)": {
        "env_var": "OPENAI_API_KEY",
        "model_name": "openai:gpt-4o"
    },
    "OpenAI (GPT-5)": {
        "env_var": "OPENAI_API_KEY",
        "model_name": "openai:gpt-5"
    },
    "Anthropic Claude": {
        "env_var": "ANTHROPIC_API_KEY",
        "model_name": "claude:claude-3-opus-20240229"
    }
}

# åˆå§‹åŒ– Session State
if "history_list" not in st.session_state:
    st.session_state.history_list = []
if "messages" not in st.session_state:
    st.session_state.messages = []
# é€é data_state.json ç®¡ç†ç›®å‰æ˜¯å¦ä½¿ç”¨é è¨­æª”èˆ‡æª”å
def load_data_state():
    try:
        if os.path.exists(DATA_STATE_PATH):
            with open(DATA_STATE_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return {"mode": "default", "file_name": ["FAQ_Default.xlsx"]}

def save_data_state(mode: str, file_names):
    try:
        # file_names should be a list
        files = file_names if isinstance(file_names, list) else [file_names]
        with open(DATA_STATE_PATH, "w", encoding="utf-8") as f:
            json.dump({"mode": mode, "file_name": files}, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

state_json = load_data_state()
if "include_default" not in st.session_state:
    st.session_state.include_default = (state_json.get("mode") == "default")
if "use_data_name" not in st.session_state:
    files = state_json.get("file_name") or state_json.get("file") or []
    st.session_state.use_data_name = files if files else []
if "current_data" not in st.session_state:
    st.session_state.current_data = None
if "file_processed" not in st.session_state:
    st.session_state.file_processed = False
if "processed_files" not in st.session_state:
    st.session_state.processed_files = []

# å‡è¨­åœ–ç‰‡è·¯å¾‘
AVATAR_PATH = "static"
CSW_AVATAR = os.path.join(AVATAR_PATH, "csw_icon.jpg")
USER_AVATAR = os.path.join(AVATAR_PATH, "user_icon.jpg")
# BOT_AVATAR = "https://your-domain.com/bot-logo.png"
# with st.chat_message("user", avatar=USER_AVATAR):

# --- 2. å·¥å…·å‡½æ•¸ ---
@st.cache_data    
def read_excel_sheets(file_path):
    if not os.path.exists(file_path):
        return None
    try:
        # è‡ªå‹•è®€å–æ‰€æœ‰å·¥ä½œè¡¨
        return pd.read_excel(file_path, sheet_name=None)
    except Exception as e:
        st.error(f"è®€å– Excel å¤±æ•—: {e}")
        return None

@st.cache_data
def extract_text_from_docx(path: str) -> str:
    try:
        return docx2txt.process(path) or ""
    except Exception as e:
        st.error(f"è®€å– DOCX å¤±æ•—: {e}")
        return ""

@st.cache_data
def extract_text_from_txt(path: str) -> str:
    try:
        with open(path, "r", encoding="utf-8", errors="ignore") as f:
            return f.read()
    except Exception as e:
        st.error(f"è®€å– TXT å¤±æ•—: {e}")
        return ""

@st.cache_data
def extract_text_from_pdf(path: str) -> str:
    try:
        reader = PdfReader(path)
        pages_text = []
        for p in reader.pages:
            try:
                pages_text.append(p.extract_text() or "")
            except Exception:
                pages_text.append("")
        return "\n".join(pages_text)
    except Exception as e:
        st.error(f"è®€å– PDF å¤±æ•—: {e}")
        return ""

@st.cache_data
def extract_text_from_pptx(path: str) -> str:
    try:
        prs = Presentation(path)
        texts = []
        for slide in prs.slides:
            for shape in slide.shapes:
                if hasattr(shape, "has_text_frame") and shape.has_text_frame:
                    texts.append("\n".join([p.text for p in shape.text_frame.paragraphs]))
        return "\n".join(texts)
    except Exception as e:
        st.error(f"è®€å– PPTX å¤±æ•—: {e}")
        return ""

def df_from_text(text: str, source_label: str) -> pd.DataFrame:
    return pd.DataFrame({"ä¾†æº": [source_label], "å…§å®¹": [text]})

def read_excel_list(file_paths):
    if not file_paths:
        return None
    combined = {}
    for p in file_paths:
        ext = os.path.splitext(p)[1].lower()
        base = os.path.basename(p)
        if ext == ".xlsx":
            data = read_excel_sheets(p)
            if not data:
                continue
            for sheet_name, df in data.items():
                if sheet_name in combined:
                    try:
                        combined[sheet_name] = pd.concat([combined[sheet_name], df], ignore_index=True)
                    except Exception as e:
                        st.error(f"åˆä½µå·¥ä½œè¡¨ {sheet_name} å¤±æ•—: {e}")
                else:
                    combined[sheet_name] = df
        elif ext == ".docx":
            text = extract_text_from_docx(p)
            df = df_from_text(text, base)
            key = base
            combined[key] = pd.concat([combined[key], df], ignore_index=True) if key in combined else df
        elif ext == ".txt":
            text = extract_text_from_txt(p)
            df = df_from_text(text, base)
            key = base
            combined[key] = pd.concat([combined[key], df], ignore_index=True) if key in combined else df
        elif ext == ".pdf":
            text = extract_text_from_pdf(p)
            df = df_from_text(text, base)
            key = base
            combined[key] = pd.concat([combined[key], df], ignore_index=True) if key in combined else df
        elif ext == ".pptx":
            text = extract_text_from_pptx(p)
            df = df_from_text(text, base)
            key = base
            combined[key] = pd.concat([combined[key], df], ignore_index=True) if key in combined else df
        else:
            st.warning(f"ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹: {base}")
    return combined if combined else None

def format_data_for_ai(data_dict):
    """å°‡ DataFrame å­—å…¸è½‰ç‚º AI æ˜“è®€çš„å­—ä¸²"""
    if not data_dict: return "ç›®å‰ç„¡åƒè€ƒè³‡æ–™ã€‚"
    full_text = ""
    for name, df in data_dict.items():
        full_text += f"\n--- {name} çŸ¥è­˜åº« ---\n"
        full_text += df.to_csv(index=False)
    return full_text

# å®šç¾©ä¸€å€‹å…§éƒ¨å‡½æ•¸ä¾†æŠŠ list è½‰å›å­—ä¸²ï¼Œæ–¹ä¾¿è¨ˆç®— Token
def get_history_string(h_list):
    return "".join([f"\næå•: {item['q']}\nå›è¦†: {item['a']}" for item in h_list])

# --- 3. åˆå§‹è³‡æ–™è¼‰å…¥é‚è¼¯ ---
# åªæœ‰åœ¨ current_data æ˜¯ None çš„æ™‚å€™æ‰å»åŸ·è¡Œè®€å–ï¼Œä¸¦ä¾ç…§ toggle ç‹€æ…‹æ±ºå®šä¾†æº
if st.session_state.current_data is None:
    # ä¾ç…§ checkbox é¸æ“‡æ±ºå®šè¼‰å…¥è³‡æ–™
    files = st.session_state.use_data_name if isinstance(st.session_state.use_data_name, list) else []
    paths = [os.path.join(DATA_FOLDER, f) for f in files if os.path.exists(os.path.join(DATA_FOLDER, f))]
    if st.session_state.include_default:
        paths = [DEFAULT_FILE] + paths
    if paths:
        st.session_state.current_data = read_excel_list(paths)
        save_data_state("default" if (st.session_state.include_default and not files) else "active", files)
    else:
        # ç„¡é¸æ“‡æ™‚ä½¿ç”¨é è¨­
        st.session_state.include_default = True
        st.session_state.current_data = read_excel_sheets(DEFAULT_FILE)
        save_data_state("default", ["FAQ_Default.xlsx"])

# --- 4. Streamlit å´é‚Šæ¬„ä»‹é¢è¨­å®š ---
with st.sidebar:
    # 1.ä¸‹æ‹‰å¼é¸å–®é¸æ“‡æ¨¡å‹
    selected_model_display = st.selectbox("é¸æ“‡æ¨¡å‹ä¾†æº",options=list(MODEL_CONFIG.keys()))
    # å–å¾—å°æ‡‰çš„é…ç½®
    config = MODEL_CONFIG[selected_model_display]

    # 2.åŠ å…¥API_KEYè¼¸å…¥æ¡†
    user_api_key = st.text_input(
        "è¼¸å…¥æ‚¨çš„ API KEY", 
        type="password",
        help="è¼¸å…¥æœ‰æ•ˆAPI_KEYå¾Œå³å¯é€²è¡Œå°è©±"
    )
    api_valid = False
    if user_api_key:
        os.environ[config["env_var"]] = user_api_key
        # ç™¼é€ä¸€æ¬¡æ¸¬è©¦è«‹æ±‚ä»¥ç¢ºèª Key æœ‰æ•ˆæ€§
        try:
            test_ak = akasha.ask(
                model=config["model_name"],
                temperature=0.1,
            )
            test = test_ak(prompt="return hi")
            st.success("API Key å·²å°±ç·’ï¼")
            api_valid = True 
        except Exception as e:
            st.error(f"API Key ç„¡æ•ˆï¼Œè«‹æª¢æŸ¥å¾Œé‡æ–°è¼¸å…¥ã€‚")
            api_valid = False
    else:
        st.warning("è«‹å…ˆè¼¸å…¥ API Key")
    st.divider()

    # 3.è³‡æ–™ä¸Šå‚³
    uploaded_files = st.file_uploader(
        "ä¸Šå‚³æ›´æ–°è³‡æ–™ (xlsx/docx/txt/pdf/pptx)", 
        type=["xlsx", "docx", "txt", "pdf", "pptx"],
        accept_multiple_files=True,
        )
    if uploaded_files:
        # åªè™•ç†å°šæœªå„²å­˜éçš„æ–°æª”æ¡ˆï¼ˆä»¥æª”ååˆ¤æ–·ï¼‰
        processed = st.session_state.processed_files if isinstance(st.session_state.processed_files, list) else []
        new_uploads = [uf for uf in uploaded_files if uf.name not in processed]
        if new_uploads:
            saved_names = []
            for uf in new_uploads:
                target_path = os.path.join(DATA_FOLDER, uf.name)
                with open(target_path, "wb") as f:
                    f.write(uf.getbuffer())
                saved_names.append(uf.name)
            # æ›´æ–°å·²è™•ç†åå–®
            st.session_state.processed_files = list(dict.fromkeys(processed + saved_names))
            # æ›´æ–°ç›®å‰çš„ä½¿ç”¨æ¸…å–®ï¼šä¿ç•™åŸæœ‰ï¼Œå†åŠ å…¥æ–°æª”ï¼ˆå»é‡ï¼‰
            existing = st.session_state.use_data_name if isinstance(st.session_state.use_data_name, list) else []
            new_list = list(dict.fromkeys(existing + saved_names))
            st.cache_data.clear()
            paths = ([DEFAULT_FILE] if st.session_state.include_default else []) + [os.path.join(DATA_FOLDER, f) for f in new_list if os.path.exists(os.path.join(DATA_FOLDER, f))]
            st.session_state.current_data = read_excel_list(paths)
            st.session_state.use_data_name = new_list if new_list else ["DEFAULT"]
            st.session_state.include_default = st.session_state.include_default if new_list else True
            save_data_state("active" if new_list else "default", new_list if new_list else ["FAQ_Default.xlsx"])
            st.success(f"âœ… å·²åŠ å…¥ {len(saved_names)} å€‹æª”æ¡ˆ")
            st.rerun()

    # ä½¿ç”¨é è¨­è³‡æ–™åº«é¸é …ï¼ˆcheckboxï¼‰
    st.session_state.include_default = st.checkbox("ä½¿ç”¨é è¨­è³‡æ–™åº«", value=st.session_state.include_default, help="æ˜¯å¦åŒ…å«é è¨­è³‡æ–™åº«")

    # åˆ—å‡ºå¯ç”¨æª”æ¡ˆä¸¦æä¾›å‹¾é¸
    def list_available_files():
        try:
            files = []
            for fn in os.listdir(DATA_FOLDER):
                path = os.path.join(DATA_FOLDER, fn)
                if os.path.isfile(path) and os.path.splitext(fn)[1].lower() in ALLOWED_EXTS and fn != os.path.basename(DEFAULT_FILE):
                    files.append(fn)
            return sorted(files)
        except Exception:
            return []

    available_files = list_available_files()
    selected = []
    for fn in available_files:
        checked = st.checkbox(fn, value=(fn in (st.session_state.use_data_name or [])), key=f"chk_{fn}")
        if checked:
            selected.append(fn)

    # è‹¥é¸æ“‡èˆ‡ç¾ç‹€ä¸åŒï¼Œæ›´æ–°è³‡æ–™èˆ‡ç‹€æ…‹æª”
    if set(selected) != set(st.session_state.use_data_name or [] ) or st.session_state.current_data is None:
        st.session_state.use_data_name = selected
        st.cache_data.clear()
        load_paths = ([DEFAULT_FILE] if st.session_state.include_default else []) + [os.path.join(DATA_FOLDER, f) for f in selected]
        if load_paths:
            st.session_state.current_data = read_excel_list(load_paths)
            save_data_state("default" if (st.session_state.include_default and not selected) else "active", selected)
        else:
            # ç„¡é¸æ“‡æ™‚è¼‰å…¥é è¨­
            st.session_state.include_default = True
            st.session_state.current_data = read_excel_sheets(DEFAULT_FILE)
            save_data_state("default", ["FAQ_Default.xlsx"])

    # é¡¯ç¤ºç›®å‰æª”æ¡ˆè³‡è¨Š
    try:
        names_list = (st.session_state.use_data_name or [])
        if st.session_state.include_default:
            names_list = ["DEFAULT"] + names_list
        names_str = ", ".join(names_list)
    except Exception:
        names_str = "DEFAULT" if st.session_state.include_default else ""
    st.caption(f"ç›®å‰ç”Ÿæ•ˆæª”æ¡ˆï¼š{names_str}")

    # æª”æ¡ˆåˆªé™¤å€
    delete_candidates = st.multiselect("é¸æ“‡è¦åˆªé™¤çš„æª”æ¡ˆ", options=available_files)
    if st.button("åˆªé™¤é¸æ“‡æª”æ¡ˆ"):
        deleted, failed = [], []
        for fn in delete_candidates:
            path = os.path.join(DATA_FOLDER, fn)
            try:
                if os.path.isfile(path):
                    os.remove(path)
                    deleted.append(fn)
                else:
                    failed.append(fn)
            except Exception:
                failed.append(fn)

        if deleted:
            # å¾ä½¿ç”¨åå–®èˆ‡å·²è™•ç†åå–®ç§»é™¤
            use_list = st.session_state.use_data_name if isinstance(st.session_state.use_data_name, list) else []
            st.session_state.use_data_name = [f for f in use_list if f not in deleted]
            processed = st.session_state.processed_files if isinstance(st.session_state.processed_files, list) else []
            st.session_state.processed_files = [f for f in processed if f not in deleted]

            # é‡æ–°è¼‰å…¥è³‡æ–™
            st.cache_data.clear()
            load_paths = ([DEFAULT_FILE] if st.session_state.include_default else []) + [os.path.join(DATA_FOLDER, f) for f in st.session_state.use_data_name if os.path.exists(os.path.join(DATA_FOLDER, f))]
            if load_paths:
                st.session_state.current_data = read_excel_list(load_paths)
                save_data_state("default" if (st.session_state.include_default and not st.session_state.use_data_name) else "active", st.session_state.use_data_name if st.session_state.use_data_name else ["FAQ_Default.xlsx"])
            else:
                st.session_state.include_default = True
                st.session_state.current_data = read_excel_sheets(DEFAULT_FILE)
                save_data_state("default", ["FAQ_Default.xlsx"])

            st.success(f"ğŸ—‘ï¸ å·²åˆªé™¤ {len(deleted)} å€‹æª”æ¡ˆ")
            st.rerun()

        if failed:
            st.warning(f"ç„¡æ³•åˆªé™¤ï¼š{', '.join(failed)}")

    # ä½¿ç”¨è€…æ‰‹å‹•é»æ“Šã€ŒXã€ç§»é™¤æª”æ¡ˆæ™‚çš„é‡ç½®
    if not uploaded_files:
        # æ¸…ç©ºä¸Šå‚³æ§ä»¶çš„å·²è™•ç†åå–®ï¼Œå…è¨±å†æ¬¡ä¸Šå‚³åŒåæª”æ¡ˆ
        st.session_state.processed_files = []
    st.divider()
    
    if st.button("æ¸…é™¤å°è©±æ­·å²"):
        st.session_state.messages = []
        st.session_state.history_list = []
        st.rerun()

# --- 5. ç”Ÿæˆ System Prompt ---
# ç¢ºä¿ context_data æ°¸é å°æ‡‰åˆ°ç›®å‰é¸ç”¨çš„è³‡æ–™ (current_data)
context_text = format_data_for_ai(st.session_state.current_data)
system_prompt = f"""
<è§’è‰²>ä½ æ˜¯ä¸€åå®¢æœäººå“¡çš„å°ˆå±¬åŠ©ç†</è§’è‰²>
<ä»»å‹™>
    1. è«‹å…ˆåˆ†ææå•ï¼Œæ˜¯éœ€è¦ä¸€èˆ¬çš„å•é¡Œé‚„æ˜¯æƒ³è¦å¾æ­·å²ç´€éŒ„æ‰¾å‡ºç›¸é—œè³‡æ–™ï¼Œå¦‚æœæ˜¯ä¸€èˆ¬çš„å•é¡Œæ­£å¸¸å›ç­”å³å¯ï¼Œå¦‚æœæ˜¯æƒ³å¾æ­·å²ç´€éŒ„æ‰¾å‡ºç›¸é—œè³‡æ–™ï¼Œå‰‡æŸ¥æ‰¾è³‡æ–™ä¸­æœ‰ç„¡é¡ä¼¼æˆ–ç›¸é—œä¹‹è³‡è¨Šã€‚
    2. è‹¥è³‡æ–™ä¸­æœ‰ç›¸é—œè³‡è¨Šï¼Œè«‹æ ¹æ“šè³‡è¨Šç”Ÿæˆå»ºè­°å®¢æœäººå“¡å¯ä»¥å›æ‡‰å®¢æˆ¶çš„å›è¦†ã€‚å¦‚æœ‰å¤šå€‹ç›¸é—œè³‡è¨Šï¼Œå‰‡ä¾ç…§ç›¸é—œåº¦é«˜åˆ°ä½æ¢åˆ—ä¸¦å€éš”é–‹ä¾†ã€‚
</ä»»å‹™>
<é™åˆ¶>
    1. ç”Ÿæˆå»ºè­°çš„å›è¦†æ™‚ï¼Œéœ€ä½¿ç”¨``` å€å¡Šå¿…é ˆå®Œæ•´é–‹å§‹ä¸¦å®Œæ•´çµæŸï¼Œå€å¡ŠçµæŸå¾Œï¼Œå¾ŒçºŒèªªæ˜æ–‡å­—è«‹ä»¥ä¸€èˆ¬ç´”æ–‡å­—è¼¸å‡ºï¼Œ
    2. ç”Ÿæˆå»ºè­°çš„å›è¦†æ™‚ï¼Œè«‹åªä½¿ç”¨ä¸­æ–‡æ–‡å­—åŠæ•¸å­—ï¼Œä¸å¾—ä½¿ç”¨ç²—é«”ã€æ–œé«”ã€åº•ç·šç­‰æ ¼å¼
    3. ç”Ÿæˆå»ºè­°çš„å›è¦†æ™‚ï¼Œæ¸…æ¥šã€è€å¿ƒã€å¾ªåºåœ°å›æ‡‰ç”¨æˆ¶æå•ï¼Œé™¤éä½¿ç”¨è€…æ˜ç¢ºè¦æ±‚ï¼Œå¦å‰‡è«‹é¿å…ï¼š
        - é•·ç¯‡èªªæ˜
        - é¡¯ç¤ºç¨‹å¼ç¢¼
        - ä½¿ç”¨å°ˆæ¥­ç¸®å¯«ã€ç”¨èª
        - è§£é‡‹ç³»çµ±é‹ä½œåŸç†æˆ–å±•ç¤ºæŠ€è¡“ç´°ç¯€
    4. æ¯æ¬¡ç”Ÿæˆå»ºè­°çš„å›è¦†æ™‚è«‹ä¾ç…§ä»¥ä¸‹æµç¨‹:
        - ä»¥"è¦ªæ„›çš„ç”¨æˆ¶æ‚¨å¥½:" é–‹é ­
        - ç°¡è¦é‡è¿°ç”¨æˆ¶å•é¡Œï¼Œè‹¥æå•è³‡è¨Šéå°‘ï¼Œå‰‡å¯å¼•å°ç”¨æˆ¶æä¾›æ›´å¤šè³‡è¨Š
        - æ ¹æ“šæå•æä¾›å…·é«”çš„è™•ç†æ­¥é©Ÿã€åŸå› èªªæ˜æˆ–å¾ŒçºŒè¡Œå‹•
        - ä»¥ç°¡çŸ­çš„é—œå¿ƒæˆ–ç¢ºèªä½œç‚ºçµå°¾
</é™åˆ¶>
<å›æ‡‰æ ¼å¼>
    - åƒè€ƒè³‡æ–™1
        - {{åƒè€ƒè³‡æ–™æ–‡ä»¶åç¨±}}
        - {{åƒè€ƒè³‡æ–™æ–‡ä»¶å…§å®¹}}

    ---

    - åƒè€ƒè³‡æ–™2
        - {{åƒè€ƒè³‡æ–™æ–‡ä»¶åç¨±}}
        - {{åƒè€ƒè³‡æ–™æ–‡ä»¶å…§å®¹}}

    ---

    å»ºè­°å›æ‡‰:

    ```
    {{å»ºè­°çš„å›æ‡‰}}
    ```
</å›æ‡‰æ ¼å¼>
<è³‡æ–™>{context_text}</è³‡æ–™>
"""

# --- 6. ä¸»ä»‹é¢é¡¯ç¤º ---
st.title("Customer Service Wingman")
st.caption("Version: v1.3.0")

# é¡¯ç¤ºç¾æœ‰çš„å°è©±ç´€éŒ„
for message in st.session_state.messages:
    avatar_icon = USER_AVATAR if message["role"] == "user" else CSW_AVATAR
    with st.chat_message(message["role"], avatar=avatar_icon):
        st.markdown(message["content"])

# --- 7. å°è©±é‚è¼¯ ---
if prompt := st.chat_input("è«‹å•æˆ‘æœ‰ä»€éº¼å¯ä»¥å”åŠ©çš„å—?"):

    # æª¢æŸ¥é©—è­‰
    if not api_valid:
        st.error("é©—è­‰å¤±æ•—ï¼šè«‹æª¢æŸ¥å¾Œåœ¨å·¦å´é¸å–®é‡æ–°è¼¸å…¥ API Key")
        st.stop()
    if not st.session_state.current_data:
        st.error("ç¼ºå°‘è³‡æ–™åº«è³‡æ–™")
        st.stop()

    # é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar=USER_AVATAR):
        st.markdown(prompt)

    # å‘¼å« Akasha å›è¦†
    with st.chat_message("assistant", avatar=CSW_AVATAR):
        with st.spinner("æ€è€ƒä¸­..."):
            try:
                ak = akasha.ask(
                    model=config["model_name"],
                    temperature=0.1,
                    max_input_tokens=20000,
                    max_output_tokens=20000
                )
                history_text = get_history_string(st.session_state.history_list)
                final_prompt = (
                    system_prompt + 
                    f"\n<æå•>\n{prompt}\n</æå•>" + 
                    f"\n<å°è©±æ­·å²>\n{history_text}\n</å°è©±æ­·å²>"
                )
                response = ak(prompt=final_prompt)
                st.markdown(response)

                # --- Token ç®¡ç†èˆ‡ä¿®å‰ª --- 
                st.session_state.history_list.append({"q": prompt, "a": response})
                
                # æ›´æ–°ä¸¦è¨ˆç®— Token
                current_h_text = get_history_string(st.session_state.history_list)
                total_content = system_prompt + prompt + current_h_text
                
                # è¿´åœˆä¿®å‰ª
                while ah.myTokenizer.compute_tokens(total_content, config["model_name"]) > 8000 and len(st.session_state.history_list) > 1:
                    st.session_state.history_list.pop(0)
                    current_h_text = get_history_string(st.session_state.history_list)
                    total_content = system_prompt + prompt + current_h_text

                # å­˜å› messages ç”¨æ–¼é¡¯ç¤º
                st.session_state.messages.append({"role": "assistant", "content": response})
            except Exception as e:
                st.error(f"æ¨¡å‹å‘¼å«å¤±æ•—: {str(e)}")